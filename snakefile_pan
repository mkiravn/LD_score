##### A snakemake pipeline to run LD score regression

#wildcard_constraints:
#   pheno_code="^\d+(?:_[a-z]*)*$"

import pandas as pd

# Read the TSV file into a pandas DataFrame
df = pd.read_csv("data/simons_phenotypes_codes.tsv", sep="\t")

# Extract the values of the "code" column into a list
code_list = df["code"].tolist()
numeric_code_list = df["ncode"].tolist()[20:40]
ns = df["N"].tolist()

import os
import re

directory = 'data/GWAS_summaries/unzipped/'

# Regular expression pattern to extract numeric code from filename
pattern = r'continuous-(\d+)-'

# List to store extracted numeric codes
numeric_codes = []

# Iterate through files in the directory
for filename in os.listdir(directory):
    # Check if the filename contains the word 'continuous'
    if 'continuous' in filename:
        # Extract numeric code from filename using regular expression
        match = re.search(pattern, filename)
        if match:
            # Append extracted numeric code to list
            numeric_codes.append(int(match.group(1)))

# Print the list of extracted numeric codes
print(numeric_codes)




rule all:
    """will return the input files needed for ldsc"""
    input:
        expand("data/GWAS_summaries/processed/{pheno_code}.info0.allchroms.pan.sumstats.tsv",pheno_code=numeric_codes),
	expand("data/sds/{pheno_code}.info0.allchroms.pan.tSDS.tsv",pheno_code=numeric_codes)


#rule all:
#    input:
#        expand("data/GWAS_summaries/raw/continuous-{pheno_code}-both_sexes-irnt.tsv.bgz",pheno_code=numeric_code_list)	

rule download_sds:
    output:
        "data/sds/SDS_UK10K_n3195_release_Sep_19_2016.tab.gz"
    shell:
        "wget https://datadryad.org/stash/downloads/file_stream/10751 -O data/sds/SDS_UK10K_n3195_release_Sep_19_2016.tab.gz"

rule unzip_sds:
    input:
        "data/sds/SDS_UK10K_n3195_release_Sep_19_2016.tab.gz"
    output:
        "data/sds/SDS_UK10K_n3195_release_Sep_19_2016.tab"
    shell:
        "gunzip -c {input} > {output}"

rule download_bscores:
    output:
        "data/bscores/CADD_bestfit.tar.gz"
    shell:
        "wget https://github.com/sellalab/HumanLinkedSelectionMaps/raw/master/Bmaps/CADD_bestfit.tar.gz -O data/bscores/CADD_bestfit.tar.gz"


# these rules only get the phenotype table - ironically though these are needed in my current rule all. 
rule download_phenotype_table:
    """downloads table of phenotypes from Simons et al. 2023, 
    https://www.biorxiv.org/content/10.1101/2022.10.04.509926v1.supplementary-material"""
    output:
        "data/simons_phenotypes.csv"
    shell:
        "wget https://www.biorxiv.org/content/biorxiv/early/2022/10/07/2022.10.04.509926/DC2/embed/media-2.csv?download=true -O data/simons_phenotypes.csv"

rule process_phenotype_table:
    input:
       "data/simons_phenotypes.csv" 
    output:
       "data/simons_phenotypes.tsv" 
    shell:
        "Rscript scripts/get_phenotypes.R {input} {output}"

rule download_phenotype_manifest:
    """downloads table of phenotypes from pan ukbb analysis"""
    output:
        tmp=temporary("data/phenotype_manifest.tsv.bgz"),
        man="data/phenotype_manifest.tsv"
    shell:
        """
        wget https://pan-ukb-us-east-1.s3.amazonaws.com/sumstats_release/phenotype_manifest.tsv.bgz -O {output.tmp} &&
        gunzip -c {output.tmp} > {output.man}
        """


#This rule unzips raw bgz files
rule unzip_bgz:
   input:
       "data/GWAS_summaries/raw/{file}.tsv.bgz"
   output:
       "data/GWAS_summaries/unzipped/{file}.tsv"
   shell:
       "gunzip -c {input} > {output}"

#rule download_pan_sumstats_files:
#    """
#    Download phenotype files
#    """
#    output:
#        "data/GWAS_summaries/raw/continuous-{pheno_code}-both_sexes-irnt.tsv.bgz"
#    shell:
#       """
#       mkdir -p data/GWAS_summaries/raw/ && \
#       wget https://pan-ukb-us-east-1.s3.amazonaws.com/sumstats_flat_files/continuous-{wildcards.pheno_code}-both_sexes-irnt.tsv.bgz \
#       -O {output} 
#       """

rule download_pan_variants:
    """
    Download variant manifest file
    """
    output:
        "data/GWAS_summaries/variants/full_variant_qc_metrics.txt.bgz"
    shell:
       """
       mkdir -p data/GWAS_summaries/variants/ && \
       wget https://pan-ukb-us-east-1.s3.amazonaws.com/sumstats_release/full_variant_qc_metrics.txt.bgz \
       -O {output} 
       """

rule unzip_pan_variants:
    """
    Download variant manifest file
    """
    input:
        "data/GWAS_summaries/variants/full_variant_qc_metrics.txt.bgz"
    output:
        "data/GWAS_summaries/variants/full_variant_qc_metrics.txt"
    shell:
       """
       gunzip -c {input} > {output}
       """

rule download_infant_mortality_sumstats:
    """rule to download summary statistics for infant mortality"""
    output:
        "data/GWAS_summaries/raw/Sumstats_byimr_Wu_2021Jun.txt.gz"
    shell:
        """
        wget ftp://ftp.biostat.wisc.edu/pub/lu_group/Projects/IMR/Sumstats/Sumstats_byimr_Wu_2021Jun.txt.gz \
        -O data/GWAS_summaries/raw/Sumstats_byimr_Wu_2021Jun.txt.gz &&
        gunzip -c data/GWAS_summaries/raw/Sumstats_byimr_Wu_2021Jun.txt.gz 
        """

rule download_ldscore_files:
    """
    Download ld score files
    """
    output:
        "data/UKBB.ALL.ldscore.tar.gz" # sub-optimal, should be all pops we want
    shell:
        "wget https://pan-ukb-us-east-1.s3.amazonaws.com/ld_release/UKBB.ALL.ldscore.tar.gz > {output}"

rule unzip_ldscore_files:
	input:
		"data/UKBB.ALL.ldscore.tar.gz"
	output: 
		"data/UKBB.ALL.ldscore/UKBB.EUR.rsid.l2.ldscore.gz"
	shell: 
		"tar â€“xvzf {input}"



rule filter_variants:
    """
    Filter variants by INFO score and chromosome
    """
    input:
        "data/GWAS_summaries/variants/full_variant_qc_metrics.txt"
    output:
        "data/GWAS_summaries/variants/variants.info{info}.chr{chrom}.pan.tsv"
    shell:
        r"""
        awk -F '\t' 'BEGIN {{OFS="\\t"}} NR==1 {{print}} ($1 == {wildcards.chrom}) && ($11 > {wildcards.info}) {{print}}' \
        {input} > {output}
        """

rule combine_sumstats:
    """
    Combine info from variant file with info from summary statistics file
    """
    input:
        variants="data/GWAS_summaries/variants/variants.info{info}.chr{chrom}.pan.tsv",
        sumstats=  "data/GWAS_summaries/unzipped/continuous-{pheno_code}-both_sexes-irnt.tsv",
        phenotypes="data/phenotype_manifest.tsv"
    output:
        combined="data/GWAS_summaries/unzipped/{pheno_code}.info{info}.chr{chrom}.pan.sumstats.tsv"
    shell:
        """
        Rscript scripts/combine_sumstats_pan.R {input.variants} \
        {input.sumstats} \
        {input.phenotypes} \
        {wildcards.pheno_code} \
        {output.combined}
        """

rule polarise_sds:
    """polarises and munges sds"""
    input:
        sds="data/sds/SDS_UK10K_n3195_release_Sep_19_2016.tab",
        sumstats="data/GWAS_summaries/unzipped/{pheno_code}.info{info}.chr{chrom}.pan.sumstats.tsv",
    output:
        polarised_sds="data/sds/{pheno_code}.info{info}.chr{chrom}.pan.tSDS.tsv",
        filtered_sumstats="data/GWAS_summaries/processed/{pheno_code}.info{info}.chr{chrom}.pan.sumstats.tsv"
    shell:
        """
        Rscript scripts/polarise_SDS_pan.R {input.sds} {input.sumstats} {output.polarised_sds} {output.filtered_sumstats}
        """ 

rule pool_sumstats:
    """pools summary statistics into one file"""
    input:
        expand("data/GWAS_summaries/processed/{pheno_code}.info{info}.chr{chrom}.pan.sumstats.tsv", pheno_code="{pheno_code}", info="{info}", chrom=range(1, 23))
    output:
        "data/GWAS_summaries/processed/{pheno_code}.info{info}.allchroms.pan.sumstats.tsv"
    shell:
        """
        find data/GWAS_summaries/processed/ -name "{wildcards.pheno_code}.info{wildcards.info}.chr*.pan.sumstats.tsv" -type f -print0 | \
        xargs -0 awk 'FNR==1 && NR>1 {{next}} 1'| \
	(sed -u 1q; \
        sort -V -k1,1 -k2,2) > {output}
        """

rule pool_SDS:
    """pools summary SDS into one file"""
    input:
        expand("data/sds/{pheno_code}.info{info}.chr{chrom}.pan.tSDS.tsv", pheno_code="{pheno_code}", info="{info}", chrom=range(1, 23))
    output:
        "data/sds/{pheno_code}.info{info}.allchroms.pan.tSDS.tsv"
    shell:
        """
        find data/sds -name "{wildcards.pheno_code}.info{wildcards.info}.chr*.pan.tSDS.tsv" -type f -print0 | \
        xargs -0 awk 'FNR==1 && NR>1 {{next}} 1'| \
        (sed -u 1q; \
	sort -V -k1,1 -k2,2) > {output}
        """
